{
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "context_length": 32768,
  "dtype": "float16",
  "embed_dim": 1024,
  "head_dim": 128,
  "hidden_dim": 3072,
  "n_heads": 16,
  "n_kv_heads": 8,
  "n_layers": 28,
  "qk_norm": true,
  "rope_base": 1000000.0,
  "transformers_version": "4.57.0",
  "vocab_size": 151936,
  "auto_map": {
    "AutoModelForCausalLM": "model.FastQwenForCausalLM"
  }
}
